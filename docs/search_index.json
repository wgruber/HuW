[
["index.html", "Höhere Statistik und Wissenschaftstheorie", " Höhere Statistik und Wissenschaftstheorie Walter Gruber 2019-05-01 "],
["vorbemerkung.html", "Vorbemerkung", " Vorbemerkung Dieses Skriptum wurde mit dem Paket bookdown erstellt. Der verwendete R-Code wird als Teil des Skriptums angeführt und kann auch direkt von diesem Dokument in ein R-Skript übernommen und ausgeführt werden. Erläuterungen zum Code beschränken sich zum Teil auf wesentliche Code-Fragmente. Für detaillierte Angaben zu diversen Funktionen ist die R-Hilfe zu verwenden. Der nachfolgende Code ist spezifisch für die Erstellung dieses Dokumentes, sowie der Bearbeitung der Beispiele im Kurs von Bedeutung. Es wird in diesem Code-Teil sichergestellt, dass die verwendeten Pakte vorhanden und geladen sind. Daher sollte dieser Code am Anfang jeder neuen R-Datei übernommen werden. Die Vorgehensweise ist: Starten von R-Studio Öffnen einer neuen R-Script-Datei Kopiere die nachfolgenden Zeilen in diese Datei Speichere die Datei mit einem entsprechenden Namen Führe diesen Code aus Füge deinen Code nach diesen Zeilen ein # Initialisierung rm(list = ls()) if (!require(&quot;pacman&quot;)) install.packages(&quot;pacman&quot;) pacman::p_load(corrplot, DAAG, dataMaid, devtools, doBy, DT, ggformula, ggplot2, gridExtra, htmlwidgets, imager, knitr, labelled, leaps, magick, MASS, NHANES, mosaic, mosaicCore, mosaicData, pander, pastecs, ppcor, reshape2, rockchalk, rpart, rpart.plot) Des Weiteren ist es von Vorteil, zu Beginn einer Auswertung/Datenanalyse mit R eine entsprechende Verzeichnisstruktur im Windows-Dateimanager festzulegen und für diese Struktur ein R-Projektfile anzulegen. Die Verzeichnisstruktur richtet sich im Allgemeinen nach der jeweiligen Analyse, folgende Vorgaben haben sich aber bewährt: Abbildung 1: Dateistruktur für R-Projekt Die Root kann dabei entweder auf der lokalen Festplatte (C:/..) oder einem Server, bzw. Cloud (../NextCloud/R Modellbildung/Images) liegen. Das Anlegen eines R-Projektes wird im RStudio durchgeführt. Abbildung 2: R-Projekt definieren Nachdem bereits eine Verzeichnisstruktur definiert wurde, kann man das Projekt in das bereits definierte Verzeichnis legen (folge den Schritten die von RStudio vorgegeben werden). Den Vorteil des projektbasierten Arbeitens werden wir im Verlauf des Kurses noch näher kennen lernen. Inhalte, Beispiele und Daten stammen teilweise aus dem Internet, u.a. (Coursera 2018), (DataCamp 2018) und den Büchern (Field 2017), (Bühner 2009) und (Bühner 2017). rm(list = ls()) graphics.off() if (!require(&quot;pacman&quot;)) install.packages(&quot;pacman&quot;) pacman::p_load(pander, mediation, SciViews) # install.packages(&quot;sjPlot&quot;) # install.packages(&quot;yaml&quot;, dependencies = TRUE) # install.packages(&quot;sjPlot&quot;, dependencies = TRUE) # install.packages(&quot;sjmisc&quot;, dependencies = TRUE) # install.packages(&quot;stringi&quot;, dependencies = TRUE) # install.packages(&quot;httpuv&quot;, dependencies = TRUE) # require(yaml) # require(sjPlot) # require(sjmisc) # options(digits=3) # Verzeichnise InitialisierenCPS85 Referenzen "],
["mediation.html", "Mediation Konzeptuelles Modell Effektgrößen der Mediation Fallbeispiel", " Mediation Die Mediatior-Analyse kann als Spezialfall der multiplen linearen Regression (MLR) gesehen werden. Wie bei der MLR wollen wir den Zusammenhang mehrerer Variablen untersuchen, wobei in der Mediator-Analyse speziell der Einfluss eines Prädiktors (des Mediators, \\(M\\)) auf die Beziehung zwischen einem weiteren Prädiktor \\(X\\) und dem Kriterium \\(Y\\) im Zentrum des Interesses steht. Bei der Mediation steht der Mediator \\((M)\\) sowohl in Beziehung zu \\(X\\) als auch zu \\(Y\\). Der direkte Effekt zwischen \\(X\\) und \\(Y\\) wird durch den indirekten Effekt über \\(M\\) erklärt, also durch \\(X \\rightarrow M \\rightarrow Y\\). Konzeptuelles Modell Eine Variable bezeichnet man als Mediatorvariable \\(M\\), wenn sie die Beziehung zweier anderer Variablen (\\(X\\) und \\(Y\\)) vermittelt/erklärt. Abbildung 15: Konzeptuelles Modell Mediation Dieser schematischen Darstellung kann man entnehmen, dass die Mediatorvariable dann einen Einfluss auf die Beziehung zwischen dem Prädiktor \\(X\\) und dem Kriterium \\(Y\\) hat, wenn sich die Beziehung zwischen \\(X\\) und \\(Y\\) (im Diagramm Pfad \\(c\\) - totaler Effekt) durch Berücksichtigung des Mediators \\(M\\) ändert. Diese Änderung ist durch den direkten Effekt (im Diagramm Pfad \\(c&#39;\\)) dargestellt. Die Stärke der Änderung und damit auch der Effekt des Mediators lässt sich darüber hinaus durch den indirekten Effekt (\\(a \\cdot b\\)) beurteilen. Um ein Mediatormodell zu prüfen, sind eine Reihe von Regressionsanalysen erforderlich: Eine Regression mit \\(X\\) als Prädiktor und \\(Y\\) als Kriterium. Der daraus resultierende Regressionskoeffizient \\(b_1\\) entspricht dem Pfad c im konzeptuellen Modell. Eine Regression mit \\(X\\) als Prädiktor und \\(M\\) als Kriterium. Der daraus resultierende Regressionskoeffizient \\(b_2\\) entspricht dem Pfad a im konzeptuellen Modell. Eine Regression mit \\(X\\) und \\(M\\) als Prädiktoren und \\(Y\\) als Kriterium. Der daraus resultierende Regressionskoeffizient \\(b_3\\) des Prädiktors \\(X\\) entspricht dem Pfad c’ und der Koeffizient \\(b_4\\) des Mediators \\(M\\) entspricht dem Pfad b im konzeptuellen Modell. Folgende Ergebnisse dieser Modelle würden für den Effekt des Mediators sprechen: Die Regressionkoeffizienten \\(b_1, b_2\\) und \\(b_3\\) (also die Pfade a, b, c im Modell) zeigen ein signifikantes Ergebnis. Der Regressionkoeffizient \\(b_3\\) muss kleiner sein als \\(b_1\\) (\\(c&#39; &lt; c\\) im Modell) Obwohl die Regressionsanalyse die grundlegende Idee der Mediationsanalyse gut zeigt, hat sie den Nachteil, dass der Effekt (Bedeutsamkeit) der Reduktion nicht wirklich klar ersichtlich ist. Häufig findet man noch folgende Kriterien (Baron and Kenny’s Method) für die Entscheidung ob eine Mediation vorliegt: Eine Mediation liegt vor, wenn die Beziehung zwischen Prädiktor und Kriterium ohne Berücksichtigung des Mediators signifikant (p &lt; .05) und mit Berücksichtigung des Mediators nicht mehr signifikant ist. Diese Entscheidungsgrundlage entspricht dem NHST-Testen (all or nothing) und kann zu maßgeblichen Fehlentscheidungen führen, denn: Ein \\(b\\)-Wert kann sich unter Umständen nur um ein wenig ändern, der dazugehörige \\(p\\)-Wert kann sich dabei jedoch ohne weiteres von signifikant auf nicht signifikant ändern! Bei einer großen Änderung des \\(b\\)-Wertes kann es aber auch durchaus vorkommen, dass beide signifikant bleiben! Als alternative Möglichkeiten zur Entscheidungsfindung haben sich folgende Verfahren bewährt: Bootstrap Test: berechnet Konfidenzintervalle für den indirekten Effekt. Liegt der Null-Effekt im CI, kann man davon ausgehen, dass keine Mediation vorliegt, anderenfalls hat man einen Mediator-Effekt gefunden. Diese Methode gibt über den Sobel-Test hinaus auch noch Auskunft über die Güte (Breite des CIs) des gefundenen Mediatior-Effektes. Wenn möglich, sollte diese Methode zur Absicherung des Effektes gewählt werden. Sobel Test: testet den indirekten Effekt (kombinierter Pfad a und b). Liefert dieser Test ein signifikantes Ergebnis, liegt eine signifikante Mediation vor. Allerdings zeigt dieser Test folgende Problembereiche: Die Annahme, dass \\(a \\cdot b\\) eine normalverteilte Stichprobenverteilung besitzt, ist vor allem bei kleinen Stichproben zweifelhaft. Der Test besitzt eine schlecht Power womit große Konfidenzintervall einhergehen. Die Präzision des Tests ist damit in Frage zu stellen! Effektgrößen der Mediation Die einfachste Effektgröße ist der Regressionskoeffizient für den indirekten Effekt und das dazugehörige CI. Der indirekte Effekt ergibt sich aus den kombinierten Effekten der Pfade a und b, also: Unstandardisierter indirekter Effekt: \\(UIE = a \\cdot b\\) Um einerseits den Effekt mit anderen Mediationsmodellen vergleichen zu können, und andererseits einen Kennwert zu berichten, der vor allem in einer Meta-Analyse verwendet werden kann, standardisiert man den indirekten Effekt (index of mediation): Standardisierter indirekter Effekt: \\(SIE = a \\cdot b \\cdot \\frac{s_{X_i}}{s_{Y}}\\) Fallbeispiel Wir betrachten zunächst folgende Hypothese: Die Motivation zu lernen ist einerseits durch die Güte des Unterrichtes und andererseits durch die Erfolge aufgrund der Lernleistung beeinflusst. Man möchte nun herausfinden, welcher der beiden Prädiktoren eine bessere Vorhersage liefert. Dazu wurden in einer Lehr-Lernstudie mit Einzeltutoren von \\(N = 10\\) StudentInnen Daten zur Motivation, Lernleistung und Unterrichtsgüte erfasst. Motivation Lernleistung Unterrichtsguete 98 4 5 98 5 6.5 103 6 7 101 7 5.5 100 8 9 106 10 6.5 111 11 8 125 12 10.5 120 14 8 115 15 10 Regressionsanalyse Wenn wir von der Hypothese ausgehen, dass die Motivation zu lernen durch die Güte des Unterrichts sowie der Lernleistung beeinflusst wird, ist es zunächst von Interesse festzustellen, ob dieses Merkmale überhaupt in Beziehung zueinander stehen. In folgenden rechnen wir daher zuerst die Korrelationen zwischen den Merkmalen. Kopier den Code in ein R-Script und führe diesen aus. Diskutiere die Ergbnisse! # library(SciViews) # fÃ¼r Funktion correlation KorTab &lt;- SciViews::correlation(DF) pander(KorTab, digits = 3) Motivation Lernleistung Unterrichtsguete Motivation 1 0.867 0.741 Lernleistung 0.867 1 0.746 Unterrichtsguete 0.741 0.746 1 plot(KorTab, type = &quot;lower&quot;, digits = 3) Wenn wir nun die Merkmale Lernleistung und Unterrichtsgüte als Regressoren und Motivation als Regressand verwenden, können wir folgendes Modell aufstellen: \\(Motivation = b_0 + b_1 \\cdot Lernleistung + b_2 \\cdot Unterrichtsguete\\) Kopiere den nachfolgenden Code in dein R-Script und führe diesen aus. Diskutiere die Ergebnisse und vergleiche diese mit nachfolgendem statistischen Pfadmodell. Mod1 &lt;- lm(Motivation ~ Lernleistung + Unterrichtsguete, data = DF) Mod1_Std &lt;- lm(scale(Motivation) ~ scale(Lernleistung) + scale(Unterrichtsguete), data = DF) # pander(summary(Mod1), digits = 3) pander(summary(Mod1_Std), digits = 3) Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -3.4e-16 0.172 -1.98e-15 1 scale(Lernleistung) 0.708 0.271 2.61 0.0349 scale(Unterrichtsguete) 0.213 0.271 0.784 0.459 Fitting linear model: scale(Motivation) ~ scale(Lernleistung) + scale(Unterrichtsguete) Observations Residual Std. Error \\(R^2\\) Adjusted \\(R^2\\) 10 0.5424 0.7712 0.7058 Die dargestellten Ergebnisse zeigen die standardisierten Koeffizienten (\\(\\beta_{LL}, \\beta_{UG}\\)). In einem statistischen Pfadmodell lassen sich die bisher gewonnenen Ergebnisse folgendermaßen zusammenfassen: Abbildung 16: statistisches Pfadmodell mit standardisierten Regressionskoeffizienten Dem Ergebnis ist weiters zu entnehmen, dass beide Prädiktoren das Ausmaß der Motivation vorhersagen, wobei die Lernleistung (\\(a = \\beta_{LL} = 0.708\\) und somit \\(R_{LL}^2 = 0.504\\)) sich als der bessere Prädiktor als die Unterrichtsgüte (\\(b = \\beta_{UG} = 0.213\\) und somit \\(R_{UG}^2 = 0.044\\)) herausstellt. Mediator-Analyse Man könnte allerdings auch von folgender Hypothese ausgehen: Je höher die Unterrichtsgüte, desto höher die Motivation und je höher die Motivation der Studenten, desto höher wird die Lernleistung ausfallen. Die Modellvorstellung wäre demnach Unterrichtsgüte \\(\\rightarrow\\) Motivation \\(\\rightarrow\\) Lernleistung. Die Motivation wäre dann nicht ein Effekt der Lernleistung, was bedeutet dass die Kausalwirkung umgekehrt verläuft. In diesem Fall würde die Unterrichtsgüte indirekt über die Mediatorvariable Motivation auf die Lernleistung wirken. Darüber hinaus ist auch anzunehmen, dass die Unterrichtsgüte auch eine direkte Wirkung auf die Lernleistung ausübt. Diese Modellvorstellung lässt sich im folgenden Pfadmodell abbilden: Abbildung 17: Pfadmodell mit standardisierten Regressionskoeffizienten in einem Mediator-Modell Diese Modellvorstellung kann man in folgenden Regressionsberechnungen zerlegen: In der ersten Regression wird die abhängige Variable (Output, Kriterium) Lernleistung durch die unabhängige Variable (Prädiktor) Unterrichtsgüte vorhergesagt. Im vorliegenden Beispiel bezeichnen wir den Steigungskoeffizienten mit \\(b_1\\). Dieser entspricht im konzeptuellen Modell dem Pfad c. Formal entspricht das Modell: \\(Lernleistung = b_0 + b_1 \\cdot Unterrichtsguete\\) Kopiere den nachfolgenden Code in dein R-Script und führe diesen aus. Diskutiere die Ergebnisse und vergleiche diese mit obigen Pfadmodell. Med_Mod_C &lt;- lm(Lernleistung ~ Unterrichtsguete, data = DF) Med_Mod_C_Std &lt;- lm(scale(Lernleistung) ~ scale(Unterrichtsguete), data = DF) # pander(summary(Med_Mod_C), digits = 3) pander(summary(Med_Mod_C_Std), digits = 3) Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 3.57e-17 0.224 1.6e-16 1 scale(Unterrichtsguete) 0.746 0.236 3.16 0.0133 Fitting linear model: scale(Lernleistung) ~ scale(Unterrichtsguete) Observations Residual Std. Error \\(R^2\\) Adjusted \\(R^2\\) 10 0.7068 0.5559 0.5004 In der zweiten Regression betrachten wir den Pfad Unterrichtsgüte zu Motivation (im konzeptuellen Modell der Pfad a), alsoe: \\(Motiviation = b_0 + b_1 \\cdot Unterrichtsguete + \\varepsilon_{Mot}\\) Kopiere den nachfolgenden Code in dein R-Script und führe diesen aus. Diskutiere die Ergebnisse und vergleiche diese mit obigen Pfadmodell. Med_Mod_A &lt;- lm(Motivation ~ Unterrichtsguete, data = DF) Med_Mod_A_Std &lt;- lm(scale(Motivation) ~ scale(Unterrichtsguete), data = DF) # pander(summary(Med_Mod_A), digits = 3) pander(summary(Med_Mod_A_Std), digits = 3) Estimate Std. Error t value Pr(&gt;|t|) (Intercept) -3.15e-16 0.225 -1.4e-15 1 scale(Unterrichtsguete) 0.741 0.238 3.12 0.0143 Fitting linear model: scale(Motivation) ~ scale(Unterrichtsguete) Observations Residual Std. Error \\(R^2\\) Adjusted \\(R^2\\) 10 0.7126 0.5486 0.4922 In der dritten Regression wird nun die Beziehung Unterrichtsgüte und Lernleistung, wie auch Motivation und Lernleistung (im konzeptuellen Modell der Pfad b und c’) überprüft. Das formale Modell lautet also: \\(Lernleistung = b_0 + b_1 \\cdot Unterrichtsguete + b_2 \\cdot Motivation + \\varepsilon_{LL}\\) Kopiere den nachfolgenden Code in dein R-Script und führe diesen aus. Diskutiere die Ergebnisse und vergleiche diese mit obigen Pfadmodell. Med_Mod_CS_B &lt;- lm(Lernleistung ~ Unterrichtsguete + Motivation, data = DF) Med_Mod_CS_B_Std &lt;- lm(scale(Lernleistung) ~ scale(Unterrichtsguete) + scale(Motivation), data = DF) # pander(summary(Med_Mod_CS_B), digits = 3) pander(summary(Med_Mod_CS_B_Std), digits = 3) Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 2.55e-16 0.17 1.5e-15 1 scale(Unterrichtsguete) 0.23 0.267 0.861 0.418 scale(Motivation) 0.696 0.267 2.61 0.0349 Fitting linear model: scale(Lernleistung) ~ scale(Unterrichtsguete) + scale(Motivation) Observations Residual Std. Error \\(R^2\\) Adjusted \\(R^2\\) 10 0.538 0.7749 0.7106 Die bis zu diesem Punkt durchgeführten Analysen lassen uns zwar den Effekt des Mediators erkennen, aber die Abschätzung, ob dieser auch statistisch signifikant ist. Im letzten Schritt unserer Analyse verwenden wir das R-Paket mediation. Kopiere nachfolgenden Code in dein Skript und führe die Zeilen aus. # library(mediation) model.0 &lt;- lm(Lernleistung ~ Unterrichtsguete, DF) model.M &lt;- lm(Motivation ~ Unterrichtsguete, DF) model.Y &lt;- lm(Lernleistung ~ Unterrichtsguete + Motivation, DF) med.out &lt;- mediation::mediate(model.M, model.Y, treat=&#39;Unterrichtsguete&#39;, mediator=&#39;Motivation&#39;, boot=TRUE, sims=500) # summary(model.0) # summary(model.M) # summary(model.Y) # summary.mediate(med.out) Abbildung 18: Ergebnis der Mediator-Analyse Der angegebene totale Effekt (\\(c = b_1 = 1.5395\\)) entspricht dem Effekt von Unterrichtsgüte auf die Lernleistung (ohne Berücksichtigung des Mediators!). Der direkte Effekt (ADE, \\(c&#39; = b_4 = 0.4743\\)) spiegelt den Effelt von Unterrichtsgüte auf Lernleistung unter Berücksichtigung der Motivation wider. Der Mediator-Effekt (ACME) entspricht der Differenz des totalen und direkten Effektes (also \\(c - c&#39; = b_1 - b_4 = 1.5395 - 0.4743 = 1.0651\\)). Das entspricht natürlich auch dem Produkt von \\(a \\cdot b = b_2 \\cdot b_3 = 3.88 \\cdot 0.275 = 1.0651\\). Wird dieser Effekt statistisch signigikant, nimmt man die Hypothese der Wirksamkeit des Mediators an. rm(list = ls()) graphics.off() if (!require(&quot;pacman&quot;)) install.packages(&quot;pacman&quot;) pacman::p_load(DT, ggplot2, interactions, pander) options(digits=3) # Verzeichnise InitialisierenCPS85 "],
["moderation.html", "Moderation", " Moderation Fördert das Spielen von gewalttätigen Videos unsoziales, bzw. aggressives Verhalten? In einer Studie wurde der Zusammenhang zwischen dem Spielen von aggressiven Videos wie z.B. Manhunt, Grand Theft Auto und MadWorld mit Aggression untersucht. Dabei wurden \\(N = 442\\) Jugendliche bezüglich ihres aggressiven Verhaltens (Aggression), den gefühls- und emotionslosen Charaktereigenschaften (Callous Unemotional Traits - CUT, CaUnTs) und der Dauer des Videospielen in Stunden pro Woche (VidGames) aufgezeichnet. Die Daten finden Sie unter Video Games.csv. ID Aggression Vid_Games CaUnTs CaUnTs_Grp 1 27 20 7 Low 2 30 34 14 Low 3 37 20 8 Low 4 29 29 13 Low 5 22 22 15 Low 6 29 34 7 Low Das Ziel der Untersuchung ist es, die Beziehung zwischen Spieldauer (= Prädiktor, Vid_Games) und Aggression (Aggression) genauer zu untersuchen. "],
["konzeptuelles-modell-1.html", "Konzeptuelles Modell Formale Beschreibung des Modells Zentrierung der Variablen", " Konzeptuelles Modell Eine Moderatorvariable ist eine Variable, welche die Beziehung zweier anderer Variablen beeinflusst. Abbildung 18: Konzeptuelles Modell Moderation Im Prinzip stellt sich also die Frage, ob eine Variable (\\(X_1\\)) einen Interaktionseffekt auf die Beziehung der beiden anderen Variablen (\\(Y, X_2\\)) bewirkt. Ein derartiger Interaktionseffekt ist im statistischen Sinne gleichzusetzen mit einem Moderationseffekt (konzeptueller Begriff). Betrachtet man die Beziehung zwischen der abhängigen Variablen (Aggression) und der erklärenden Variablen (Vid_Games): p &lt;- ggplot(DF, aes(x = Vid_Games, y = Aggression)) + geom_point() + geom_smooth(method = lm, se = FALSE) + theme_bw() print(p, comment = FALSE) SumMod1 &lt;- summary(lm(Aggression ~ Vid_Games, data = DF)) pander(SumMod1) Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 34.84 1.96 17.77 1.166e-53 Vid_Games 0.2385 0.08552 2.789 0.005515 Fitting linear model: Aggression ~ Vid_Games Observations Residual Std. Error \\(R^2\\) Adjusted \\(R^2\\) 442 12.5 0.01737 0.01514 scheint die Spieldauer und Aggression nur in einem geringen Ausmaß miteinander in Beziehung zu stehen. Die aufgeklärte Varianz beträgt gerade einmal 1.737%. Ein anderes Bild ergibt sich jedoch, wenn man die Daten unter Berücksichtigung der Variablen CaUnTs betrachtet. Teilt man die Variable CaUnTs z.B. durch einen Mediansplit in zwei Gruppen (CaUnTs_Grp = Low und High), zeigt sich bereits ein sehr unterschiedliches Bild: p1 &lt;- ggplot(DF, aes(x = Vid_Games, y = Aggression, color = CaUnTs_Grp)) + geom_point() + geom_smooth(method = lm, se = FALSE) + theme_bw() print(p1, comment = FALSE) Durch die Trennung können folgende Eigenschaften in den Daten beobachtet werden: Bei Personen die keine CUT aufweisen, besteht keine Beziehung der Spieldauer und der Aggression. Personen die einen CUT aufweisen, zeigen eine positive Beziehung, d.h. je mehr Zeit sie spielen, desto höher wird ihr Aggressionslevel. Die CUT beeinflusst (moderiert) daher die Beziehung der Spieldauer und Aggression. Den Effekt der Variablen CaUnTs (Moderatorvariablen) kann man sich gut durch folgende Darstellung vorstellen: Mod_1 &lt;- lm(Aggression ~ Vid_Games * CaUnTs, data=DF) # plotPlane(model = Mod_1, plotx1 = &quot;Vid_Games&quot;, plotx2 = &quot;CaUnTs&quot;) Abbildung 19: Moderator-Effekt Dass die Moderatorvariable einen Einfluss auf die Beziehung zwischen Vid_Games und Aggression hat, zeigt sich vor allem dadurch dass bei niedrigen CaUnTs-Werten eine negative und bei hohen CaUnTs-Werten eine positive Beziehung zwischen Spieldauer und Aggression besteht. Damit wird auch der Kernpunkt eines Moderationseffektes angesprochen. Ein Moderationseffekt liegt vor, wenn sich die Beziehung zweier Variablen vom Wertebereich des Moderator abhängig ist. Formale Beschreibung des Modells Das lineare Modell einer Moderationsanalyse erweitert die bereits bekannte multiple Regression um den Interaktionsterm: \\(\\widehat{Aggression}_i = (b_0 + b_1 \\cdot Spieldauer_i + b_2 \\cdot Callous_i + b_3 \\cdot Interaktion_i)\\) In den meisten Statistikprogrammen (R, SPSS, SAS, etc.) gibt es Pakete/Makros, mit denen die Moderationsanalyse (u.v.m) speziell aufbereitet wird. Im vorliegenden Fall sollte anhand des einfachen Modells die grundlegende Idee vorgestellte werden. Bei der obigen Formel sind bis auf die Interaktion alle Daten bereits im geladenen Datenmaterial verfügbar. Die Interaktion kann nun sehr leicht aus diesen Daten berechnet und als weitere Variable im Datenframe abgespeichert werden. Dazu braucht man nur die beiden Variablen Vid_Games und CaUnTs multiplizieren und speichern. DF$IA &lt;- DF$Vid_Games*DF$CaUnTs Im nachfolgenden Ergebnis ist vor allem der Interaktionseffekt von Interesse. Ist die Interaktion signifikant, kann man davon ausgehen, dass ein bedeutsamer Moderationseffekt vorliegt. pander(summary(Mod_1)) Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 33.12 3.427 9.664 3.729e-20 Vid_Games -0.3336 0.1508 -2.212 0.0275 CaUnTs 0.1689 0.161 1.049 0.2947 Vid_Games:CaUnTs 0.02706 0.006981 3.877 0.0001221 Fitting linear model: Aggression ~ Vid_Games * CaUnTs Observations Residual Std. Error \\(R^2\\) Adjusted \\(R^2\\) 442 9.976 0.3773 0.373 Bei vorliegender signifikanter Interaktion kann durch eine Simple Slope Analyse (SSA) die Beziehung zwischen Prädiktor und Kriterium für verschiedene Werte des Moderators untersucht werden. Häufig werden dafür drei Werte des Moderators (niedrig = \\(\\bar{x}_{Mod} - sd_{Mod}\\), mittel = \\(\\bar{x}_{Mod}\\), hoch = \\(\\bar{x}_{Mod} + sd_{Mod}\\)) verwendet. In der folgenden Abbildung wurden die Datenpunkte noch zusätzlich nach Ihrer Ausprägung (Größe) bei CaUnTs gewichtet. # library(interactions) # # https://cran.r-project.org/web/packages/jtools/vignettes/interactions.html interact_plot(Mod_1, pred = &quot;Vid_Games&quot;, modx = &quot;CaUnTs&quot;, plot.points = TRUE) Für eine feiner Aufteilung, bzw. Darstellung des Wirkungsbereiches vom Moderator kann über die Johnson und Neymann Methode sehr viele Werte des Moderators berechnen werden. Die entsprechenden \\(b\\)’s werden ermittelt und daraus Signifikanz-Zonen berechnet. Damit werden die Werte des Moderators ermittelt, ab welchen der Prädiktor ein signifikantes Ergebnis liefert. Mod_SS &lt;- lm(Aggression ~ Vid_Games + CaUnTs + (Vid_Games * CaUnTs), data=DF) SS_Res &lt;- sim_slopes(Mod_SS, pred = Vid_Games, modx = CaUnTs, johnson_neyman = TRUE) johnson_neyman(Mod_SS, pred = Vid_Games, modx = CaUnTs, alpha = 0.01) JOHNSON-NEYMAN INTERVAL When CaUnTs is OUTSIDE the interval [-5.35, 18.86], the slope of Vid_Games is p &lt; .01. Note: The range of observed values of CaUnTs is [0.00, 43.00] Zentrierung der Variablen Durch die Berücksichtigung der Interaktion, bekommen die Koeffizienten eine spezielle Bedeutung. Ein Prädiktor \\(X_i\\) repräsentiert die Regression des Kriteriums, wenn die anderen Prädiktoren \\(X_{j \\ne i}\\) gleich Null sind! Im Beispiel: \\(b_1\\) entspricht dem Koeffizienten einer Regression wenn CaUnTs gleich Null ist, also keine Gefühls und emotionslosen Charaktereigenschaften aufweist. \\(b_2\\) entspricht dem Koeffizienten einer Regression wenn VidGames gleich Null ist, also 0 Stunden Video gespielt hat. Im gegebenen Beispiel sind für beide Prädiktoren Null-Werte durchaus möglich. Würde man aber anstelle der Charaktereigenschaften die Herz-Rate der Jugendlichen messen, wäre ein Wert von Null nicht sinnvoll. Aus diesem Grund werden in einer Moderationsanalyse die Prädiktoren transformiert. Man zentriert die Daten auf die Abweichungen des grand averages. Eigenschaften der Zentrierung Das Zentrieren der Prädiktoren ist ähnlich der bekannten z-Transformation, wobei bei der Zentrierung die Division durch die Standardabweichung nicht relevant ist. Formal entsprechen die zentrierten Daten also: \\(X^C_{1i} = X_{1i} - \\bar{X}_{11}\\) Die Zentrierung hat keinen Einfluss auf den Koeffizienten, welcher die meisten Variablen (highest-order-predictor) verknüpft. Im gegebenen Beispiel entspricht das dem Koeffizienten \\(b_3\\), also der Interaktion. Für die Koeffizienten \\(b_1\\) und \\(b_2\\) bewirkt die Zentrierung: \\(b_2\\) zeigt den Effekt zwischen Agression und CUT, wenn jemand die durchschnittliche Spielzeit mit Videospielen verbringt. \\(b_1\\) zeigt den Effekt zwischen Agression und Spieldauer, wenn jemand den durchschnittlichen CUT-Wert haben würde. Gründe für Zentrierung Aus Gründen der Interpretierbarkeit, z.B. \\(y\\) = verbale Fähigkeiten eines Kindes, \\(x_1\\) = Vokabular von der Mutter, \\(x_2\\) = Alter des Kindes: \\(b_0\\) ist nicht sinnvoll interpretierbar, wenn \\(x_1 = 0\\) und \\(x_2 = 0\\) \\(b_0\\) ist aber dann sinnvoll interpretierbar, wenn die Variablen zentriert wurden, denn dann sind die Werte 0 für beide Variablen eben der Mittelwert der zentrierten Variablen! \\(b_1\\) entspricht der Steigung von \\(x_1\\) unter der Annahme eines durchschnittlichen Wertes von \\(x_2\\). Liegt keine Moderation vor, wir \\(b_1\\) konsistent über alle Werte der \\(x_2\\)-Verteilung sein. Liegt ein Moderationseffekt vor, ist \\(b_1\\) nicht konsistent über die Verteilung der \\(x_2\\)-Werte. Aus statistischen Gründen: korrelieren \\(x_1\\) und \\(x_2\\) dann kann es sein, dass auch die Interaktion \\(x_1 \\cdot x_2\\) hoch korreliert! Wenn zwei Prädiktoren in einem GLM hoch miteinander korrelieren, dann sind sie im wesentlichen redundant. Es liegt eine hohe Multikollinearität vor! Es wird auch schwierig, die \\(b\\)-Werte den jeweiligen Prädiktoren zuzuordnen. Bei Zentrierung der Daten kann dieses Problem entschärft werden. Interpretation der \\(b\\)’s Die Zentrierung ermöglicht die Interpretation der Koeffizienten \\(b_1\\) und \\(b_2\\) (lower-order-predictors) auch dann, wenn Null-Werte bei Prädiktoren nicht sinnvoll zu interpretieren sind! Die Interpretation von lower-order-predictors ist nur sinnvoll, wenn die higher-order-predictors nicht signifikant sind! Bei zentrierten Prädiktoren können die \\(b\\)’s von einzelnen Prädiktoren folgendermaßen interpretiert werden: sie zeigen den Effekt des jeweiligen Prädiktors beim Mittelwert der Stichprobe. sie zeigen den durchschnittlichen Effekt des Prädiktors über die Spannweite der Werte des anderen Prädiktors. Bemerkung zu 2: stellen Sie sich vor, dass Sie für jeden möglichen Wert der Spieldauer (VidGames = von 0 bis max(Spieldauer)) jeweils ein lineares Modell rechnen, also ein Modell zur Vorhersage für Aggression durch CUT für die Personen die 0 Std. gespielt haben. Dann dasselbe Modell für jene die 1 Std. gespielt haben, etc. Dadurch ergeben sich z.B. \\(N\\) unterschiedliche \\(b\\)’s, wobei jedes davon den Zusammenhang zwischen CUT und Aggression für unterschiedlich lange Spieldauer zeigt. Würde man den Mittelwert dieser \\(b\\)’s berechnen, dann wäre dieser Wert gleich dem \\(b\\)-Wert für CUT (zentriert) wenn dieser im Moderationsmodell gemeinsam mit der zentrierten Spieldauer (VidGames) und der Interaktion berechnet wird! Interaktion Besteht eine signifikante Interaktion zwischen den beiden Prädiktoren, liegt ein Moderationseffekt vor! Ist die Interaktion \\(CaUnTs \\times Vid\\_Games\\) ein signifikanter Prädiktor für Agression, dann wissen wir zwar dass ein Moderationseffekt vorliegt, aber nicht in welcher Weise! Es könnten folgende Zusammenhänge bestehen: Es könnte sein, dass die Spieldauer immer einen negativen Einfluss auf den Aggressions hat, aber diese Beziehung bei höher werdenden CUT noch wesentlich verstärkt wird. Es könnte sein, dass bei Personen mit niedrigem CUT die Spielzeit die Agression verringert, aber bei Personen mit hohen CUT die Aggression verstärkt. Die Simple Slope Analysis (SSA) bietet bei der Interpretation der Interaktionseffekte eine wesentliche Hilfestellung. "],
["motivation.html", "Motivation", " Motivation Die Kovarianzanalyse (ANCOVA) ist ein Spezialfall der ANOVA. Beide werden verwendet, um die Auswirkungen kategorischer Variablen (Faktoren) auf eine intervall- oder ratio-level abhängige Variable zu testen. Die ANCOVA gibt uns jedoch die zusätzliche Möglichkeit, gleichzeitig die Wirkung anderer kontinuierlicher Variablen auf die abhängige Variable zu beurteilen oder zu kontrollieren. Kontinuierliche Variablen, die als Unabhängige in einem ANOVA-Design enthalten sind und die mit einer abhängigen Variablen kovariabel sind, nennt man Kovariablen. Bei der ANCOVA geht es im Wesentlichen darum, die Fehlervarianz bei randomisierten Gruppenexperimenten weiter zu verringern. ANCOVA wird jedoch häufiger eingesetzt, wenn eine Randomisierung nicht möglich ist. In diesen Fällen müssen wir uns oft mit so genannten “nicht-äquivalenten” (nicht zufällig zugeordneten) Gruppen zufrieden geben. Per Definition können sich solche Gruppen in erheblicher Weise unterscheiden, auch bei Merkmalen, die die Ergebnisvariable beeinflussen können. Solange sie nicht berücksichtigt werden, kann das Vorhandensein dieser Hintergrund- oder Fremdvariablen die Fehlervarianz erhöhen, unseren “Signal-Rausch-Abstand” verringern und es letztendlich schwieriger machen, einen echten Unterschied zwischen den Gruppen zu erkennen. "],
["kovarianzanalyse.html", "Kovarianzanalyse Voraussetzungen Berechnung einer ANCOVA Nützliche Graphen Homogenität der Steigung Bericht der Ergebnisse", " Kovarianzanalyse Im folgenden betrachten wir ein Beispiel, welches die Auswirkungen von Viagra auf den Libido untersucht. Es ist naheliegend anzunehmen, dass auch andere Faktoren (wie andere Medikamente, Müdigkeit, etc.) den Libido beeinflussen. Wenn diese Variablen (die Kovariablen) gemessen werden, ist es möglich, den Einfluss, den sie auf die abhängige Variable haben, durch Einbeziehung in das Regressionsmodell zu steuern/kontrolliern. Ziel ist es, den Effekt der Kovariaten auf die Zielvariable zu entfernen. Durch diese Maßnahme sollte sich die Wirkungsweise der unabhängigen Variablen (Viagra) auf den Libodo besser zeigen. Es gibt im Wesentlichen zwei Gründe1 für die Aufnahme von Kovariablen in die ANOVA: Reduzierung der Fehlervarianz: in der ANOVA und beim t-Tests wird die Wirkung eines Experiments anhand der erklärbaren Variabilität in den Daten, mit der nicht erklärbaren Variabiliät verglichen. Wenn ein Teil dieser unerklärten Varianz (SSR) einer anderen Variablen (Kovariablen) zugeordnet werden kann, reduziert sich die Fehlervarianz. Damit kann die Wirkung der unabhängigen Variable (SSM) genauer beurteilt werden. Eliminierung von Confounds: in jedem Experiment kann/wird es Variablen geben, welche nicht gemessen/erhoben wurden, die aber die Ergebnisse der Zielvariablen durchaus beeinflussen können. Sind diese bekannt, kann mit Hilfe der ANCOVA dieser Einfluss beseitigt werden. Im vorliegenden Beispiel gehen wir davon aus, dass der Libido der Sexualpartner den eigenen Libido beeinflusst2. Das entsprechende Regressionsmodell erweitert sich demnach zu: \\(libido_i = b_0 + b_3 \\cdot covariate_i + b_2 \\cdot high_i + b_1 \\cdot low_i + \\varepsilon_i\\) Voraussetzungen Die ANCOVA hat die gleichen Annahmen wie ANOVA, zu welchen es jedoch noch zwei wichtige zusätzliche Überlegungen gibt: Unabhängigkeit von der Kovariablen- und dem Treatmenteffekt. Abbildung 4-A zeigt die bereits aus der ANOVA bekannte Zerlegung der Varianzen in eine Fehlervarianz und einer Treatmentvarianz. Abbildung 4-B stellt eine ideale Voraussetzung für die Verwendung einer Kovariaten dar. Hierbei wird durch die Kovariate ein Teil der Fehlervarianz erklärt, ohne den Effekt des Treatment zu beeinflussen. Abbildung 4-C hingegen zeigt das Problem bei einer fälschlicherweise verwendeten Kovariaten. Die Kovariate verringert zwar nach wir vor die Fehlervarianz, aber gleichzeitig wird auch der Treatmenteffekt beeinflusst. Statistisch gesehen können wir nur festhalten, dass die Kovariate und das Treatment Varianz gemeinsam erkären. Eine Trennung dieser gemeinsamen Varianz in Anteile Viagra und Kovariate ist nicht möglich! Eine einfache Möglichkeit die Kovariate auf ihre Eigenschaft zu prüfen, ist ein einfacher Mittelwertsvergleich (t-Test, ANOVA) der nach Viagragruppen aufgeteilten Kovariaten. Wenn die Gruppen sich nicht unterscheiden, kann von einer Unabhängigkeit ausgegangen werden und sofern die anderen Voraussetzungen erfüllt sind, die Kovariate verwendet werden. Auch durch eine Randomisierung der Gruppenzuordnung kann man unerwünschte Effekte (in Bezug auf die Wirkung der Kovariaten) zwischen den Gruppen evtl. vermeiden. Abbildung 20: Wirkungsweise von Kovariate Zum besseren Verständnis der mit den ANOVA-Verfahren verbundenen Varianzaufteilung betrachten wir nochmals im Detail die Eigenschaften der verschiedenen Varianzanteile. Die Gesamtvarianz (im vorigen Graphen die Varianz von Werten im Libido) wird folgendermaßen ermittelt: Abbildung 21: Totale Quadratsumme Die Treatmentvarianz (im vorigen Graphen die Varianz die durch das Treatment erklärt wird) entspricht der Variabilität der Mittelwerte der jeweiligen Gruppen (in unserem Fall der Dosierungsstufen): Abbildung 22: Treatmentquadratsumme Die Fehlervarianz wird aus den durchschnittlichen Abweichungen der beobachteten Werte zu den jeweiligen Gruppenmittelwerten bestimmt (geschätzt). Anhand dieser Darstellung wird auch klar, warum die Varianzgleichheit über die Gruppen hinweg gleich sein sollte. Wäre das nämlich nicht gegeben, würde die Additivität (\\(QS_1 + \\cdots + QS_k\\) nicht gegeben sein. Abbildung 23: Fehlerquadratsumme Homogenität der Regressionssteigungen. Bei einer ANCOVA wird die Gesamtbeziehung zwischen dem Ergebnis (abhängige Variable) und der Kovariablen analysiert. D.h., es wird eine Regressionslinie an den gesamten Datensatz angepasst und man ignoriert, zu welcher Gruppe eine Person gehört. Bei der Anpassung dieses Gesamtmodells gehen wir daher davon aus, dass diese Gesamtbeziehung für alle Teilnehmergruppen gilt. Diese Annahme ist für die ANCOVA sehr wichtig. Der beste Weg diese Annahme zu kontrollieren, ist eine Darstellung der Kovariablen (Partner’s Libido) auf der einen und dem Ergebnis (Libido) auf der anderen Achse, getrennt nach den Gruppen (Dosierung). Die Regressionslinien sollten dann mehr oder weniger gleich aussehen (d.h. die Werte von \\(b\\) in jeder Gruppe sollten gleich sein). Im nachfolgender Darstellung wäre diese Voraussetung nicht erfüllt! Abbildung 24: Verletzung der Homogenitätsbedingung Berechnung einer ANCOVA Bei der Berechnung einer ANCOVA sollten folgende Schritte durchgeführt werden: Grafischen Darstellung der Daten und der Berechnung einiger deskriptiver Statistiken. Dabei sollten auch die Verteilungsannahmen überprüfen und den Levene-Test durchgeführt werden (Homogenitätstest). Überprüfen der Kovariable und alle unabhängigen Variablen auf Unabhängigkeit, d.h. eine ANOVA mit der Kovariablen als Ergebnis und alle unabhängigen Variablen als Prädiktoren durchführen. Damit wird sichergestellt, dass sich die Kovariable auf den Ebenen dieser Variablen nicht signifikant unterscheidet. Wenn man ein signifikantes Ergebnis erhält, dann ist die Analyse bei diesem Schritt beendet3. Durchführen der ANCOVA. Berechnung der Kontraste oder post hoc-Tests (falls signifikante Ergebnisse vorliegen). Überprüfen der Homogenität der Regressionssteigungen. Dies kann graphisch (siehe oben) durchgeführt werden, oder man kann auch die ANCOVA erneut ausführen und die Interaktion zwischen der unabhängigen Variable und der Kovariablen ins Modell aufnehmen. Wenn diese Interaktion signifikant ist, kann man nicht von einer Homogenität der Regressionsflanken ausgehen! Deskriptive, graphisch und Homogenität Um die Verteilung von Daten darzustellen, kann man z.B. Boxplots für Libido als auch für Libido des Partners erzeugen. Darüber hinaus ist es hilfreich, die Beziehung zwischen der Ergebnisvariablen und der Kovariablen innerhalb jeder Gruppe zu betrachten (dies sagt uns etwas über die Homogenität der Steigungen aus). Die Boxplots zeigen den Libido bei den Teilnehmern und ihren Partnern über die drei Dosen von Viagra. Die Libido scheint für die Teilnehmer mit zunehmender Dosis von Viagra zu steigen, aber das Gegenteil gilt für ihre Partner. Neben der graphischen Darstellung sind auch die deskriptiven Werte aufschlussreich, da diese Kennwerte wie die Streung (\\(sd\\)) und Mittelwerte (\\(\\bar{x}\\)), Konfidenzintervalle (\\(CI\\)), etc. ausgegeben werden. median mean SE.mean CI.mean.0.95 var std.dev coef.var 2 3.222 0.5958 1.374 3.194 1.787 0.5547 median mean SE.mean CI.mean.0.95 var std.dev coef.var 4.5 4.875 0.5154 1.219 2.125 1.458 0.299 median mean SE.mean CI.mean.0.95 var std.dev coef.var 4 4.846 0.5867 1.278 4.474 2.115 0.4365 median mean SE.mean CI.mean.0.95 var std.dev coef.var 4 3.444 0.6894 1.59 4.278 2.068 0.6005 median mean SE.mean CI.mean.0.95 var std.dev coef.var 2.5 3.125 0.6105 1.444 2.982 1.727 0.5526 median mean SE.mean CI.mean.0.95 var std.dev coef.var 2 2 0.4529 0.9868 2.667 1.633 0.8165 median mean SE.mean CI.mean.0.95 var std.dev coef.var 4 4.367 0.3571 0.7304 3.826 1.956 0.448 median mean SE.mean CI.mean.0.95 var std.dev coef.var 2.5 2.733 0.3388 0.6929 3.444 1.856 0.6789 Der Test auf Varianzhomogeniät wird mit dem Levene’s-Test durchgeführt. Dabei zeigt sich der Test mit dem Median als zentraler Kennwert robuster als die Schätzung durch den Mittelwert (Bemerkung: man kann auch das Verhältnis der größten zur kleinsten Varianz4 (aus deskriptiver Statistik) bilden und in einer entsprechenden Tabelle auf Signifikanz prüfen). # library(car) fÃ¼r Levenes Test pander(leveneTest(viagraData$libido, viagraData$dose, center = median)) # fÃ¼r robustere SchÃ¤tzung! Levene’s Test for Homogeneity of Variance (center = median) Df F value Pr(&gt;F) group 2 0.3256 0.7249 27 NA NA pander(leveneTest(viagraData$libido, viagraData$dose, center = mean)) Levene’s Test for Homogeneity of Variance (center = mean) Df F value Pr(&gt;F) group 2 0.7112 0.5 27 NA NA Unabhängigkeit Die Unabhängigkeit kann man relativ einfach durch eine ANOVA mit partnerLibido als Ergebnis und Dosis als Prädiktor durchführen. Analysis of Variance Model Df Sum Sq Mean Sq F value Pr(&gt;F) dose 2 12.77 6.385 1.979 0.1577 Residuals 27 87.1 3.226 NA NA Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 3.444 0.5987 5.753 4.062e-06 doseLow Dose -0.3194 0.8727 -0.366 0.7172 doseHigh Dose -1.444 0.7788 -1.855 0.0746 Fitting linear model: partnerLibido ~ dose Observations Residual Std. Error \\(R^2\\) Adjusted \\(R^2\\) 30 1.796 0.1279 0.06326 ## $fill ## [1] FALSE ## ## attr(,&quot;class&quot;) ## [1] &quot;guides&quot; Bei den Koeffizienten (Estimate) des Modells entspricht der Intercept den Mittelwert der ersten Dosierungsstufe (= Placebo) und die weiteren den jeweiligen Abstand zum Mittelwert der Placebodosierung! Berechnung ANCOVA Nach Überprüfung der Voraussetzungen können wir die ANCOVA berechnen. Anova Table (Type III tests) Sum Sq Df F value Pr(&gt;F) (Intercept) 12.94 1 4.257 0.0492 partnerLibido 15.08 1 4.959 0.03483 dose 25.19 2 4.142 0.02745 Residuals 79.05 26 NA NA Betrachtet man die Signifikanz-Werte, so ist klar, dass die Kovariable die abhängige Variable signifikant vorhersagt, da \\(F(1,26) = 4.96, p = .035\\) ist. Es ist also davon auszugehen, dass der Libido der Person durch die Libido des Partners beeinflusst wird. Interessant ist, dass nach Berücksichtigung der Wirkung des Libido’s vom Partners die Wirkung von Viagra signifikant ist (\\(F(2,26) = 4.14, p = .028\\)). Wenn wir das nochmals mit den Ergebnissen einer ANOVA (also ohne Berücksichtigung der Kovariaten vergleichen), stellen wir fest, dass durch die Kovariate sich ein nicht signifikantes in ein signifikantes Ergebnis geändert hat. pander(car::Anova(aov(libido ~ dose, data = viagraData), type = &quot;III&quot;)) Anova Table (Type III tests) Sum Sq Df F value Pr(&gt;F) (Intercept) 93.44 1 26.81 1.891e-05 dose 16.84 2 2.416 0.1083 Residuals 94.12 27 NA NA pander(summary.lm(aov(libido ~ partnerLibido + dose, data = viagraData))) Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 1.789 0.8671 2.063 0.0492 partnerLibido 0.416 0.1868 2.227 0.03483 doseLow Dose 1.786 0.8494 2.102 0.04535 doseHigh Dose 2.225 0.8028 2.771 0.01018 Fitting linear model: libido ~ partnerLibido + dose Observations Residual Std. Error \\(R^2\\) Adjusted \\(R^2\\) 30 1.744 0.2876 0.2055 Interpretation ANCOVA Es scheint ziemlich klar zu sein, dass die signifikante ANOVA einen Unterschied zwischen der Placebogruppe und den beiden experimentellen Gruppen widerspiegelt. Anova Table (Type III tests) Sum Sq Df F value Pr(&gt;F) (Intercept) 76.07 1 25.02 3.342e-05 partnerLibido 15.08 1 4.959 0.03483 dose 25.19 2 4.142 0.02745 Residuals 79.05 26 NA NA Dieser Effekt kann damit begründet werden, da niedrig- und hochdosierten Gruppen sehr ähnliche Mittel haben (\\(\\bar{x}_{Low} = 4.88\\), \\(\\bar{x}_{High} = 4.85\\), während der Mittelwert der Placebogruppe bei \\(\\bar{x}_{Placebo} = 3.22\\) viel niedriger ist. Libido Libido_Partner Libido_Adj Placebo 3.222 3.444 2.926 Low Dose 4.875 3.125 4.712 High Dose 4.846 2 5.151 Eigentlich können wir aber diese Gruppenmittel nicht interpretieren, da sie nicht um den Effekt der Kovarianz bereinigt wurden. Diese ursprünglichen Mittel sagen uns nichts über die Gruppenunterschiede, die sich in der signifikanten ANCOVA widerspiegeln! Daher müssen für diesen Vergleich die um den Effekt der Kovariaten bereinigten Mittelwerte verwendet werden. Diese sind in obiger Tabelle in Spalte Libido_Adj angegeben! Geplante Kontraste Für die Berechnung von Kontrasten können entweder vordefinierte Kontrastcodes, oder eigene Kontrastekodierungen angegeben werden5. In R lässt sich z.B. ein Kontrast durch folgende Eingabe definieren: # für orthogonale Kontraste nach Helmert contrasts(viagraData$dose) &lt;- contr.helmert(3) # für Vergleich von Placebo vs. low- und highdose (-2,1,1), sowie low vs. high contrasts(viagraData$dose) &lt; -cbind(c(-2,1,1), c(0,-1,1)) Estimate Std. Error t value Pr(&gt;|t|) (Intercept) 3.126 0.625 5.002 3.342e-05 partnerLibido 0.416 0.1868 2.227 0.03483 dose1 0.6684 0.24 2.785 0.009852 dose2 0.2196 0.4056 0.5414 0.5928 Die Ausgabe des zweiten - oben angegebenen - Kontrastes lässt sich folgendermaßen interpretieren: die erste Variable (Dosis1) vergleicht die Placebogruppe mit der Niedrig- und Hochdosisgruppe. Als solches vergleicht es den angepassten Mittelwert der Placebogruppe (\\(\\bar{x}_{Placebo} = 2.93\\)) mit dem Durchschnitt der angepassten Mittelwerte für die niedrig- und hochdosierten Gruppen (\\((4.71+5.15)/2 = 4.93\\)). der b-Wert für die erste Variable sollte daher die Differenz zwischen diesen Werten sein: \\(4.93 - 2.93 = 2\\). dieser Wert wird durch die Anzahl der Gruppen innerhalb des Kontrastes (d.h. 3) dividiert und somit \\(2/3 = .67\\) (wie in der Ausgabe) beträgt. Die zugehörige \\(t\\)-Statistik ist signifikant, was darauf hindeutet, dass sich die Placebogruppe signifikant vom kombinierten Mittelwert der Viagra-Gruppen unterschied. die zweite Variable (Dosis2) vergleicht die niedrig- und hochdosierten Gruppen, so dass der \\(b\\)-Wert die Differenz zwischen den eingestellten Mitteln dieser Gruppen sein sollte: \\(5.15 - 4.71 = 0.44\\). Dieser Wert wird durch die Anzahl der Gruppen innerhalb des Kontrastes (d.h. 2) dividiert wird und somit \\(0,44/2 = 0,22\\) (wie in der Ausgabe) beträgt. die zugehörige \\(t\\)-Statistik ist nicht signifikant (\\(p = .590\\)), was darauf hindeutet, dass die hochdosierte Gruppe keine signifikant höhere Libido produzierte als die niedrigdosierte Gruppe. der Wert für die Kovariable beträgt (\\(b = 0.416\\)). Wenn also der Libido eines Partners um eine Einheit zunimmt, sollte der Libido der Person um knapp eine halbe Einheit zunehmen (obwohl es nichts gibt, was auf einen kausalen Zusammenhang zwischen den beiden hinweist). das Vorzeichen dieses Koeffizienten zeigt in welche Richtung die Beziehung zwischen der Kovariablen und dem Ergebnis geht. Da der Koeffizient in diesem Beispiel positiv ist, bedeutet dies also, dass die Libido des Partners in einem positiven Verhältnis zur Libido des Teilnehmers steht: mit dem einen steigt auch der andere. ein negativer Koeffizient würde das Gegenteil bedeuten: wenn einer steigt, sinkt der andere. Interpretation Kovariate Für die Interpretatiom der Kovariaten verwendet man am besten die Parameterschätzungen (\\(b\\)) in folgender Weise: wenn der \\(b\\)-Wert für die Kovariable positiv ist, haben die Kovariable und die Ergebnisvariable eine positive Beziehun, also mit zunehmenden Werten der Kovariable steigt auch das Ergebnis! wenn der \\(b\\)-Wert negativ ist, bedeutet das das Gegenteil. Für diese Daten war der \\(b\\)-Wert positiv, was darauf hindeutet, dass mit zunehmender Libido des Partners auch die Libido des Teilnehmers steigt. Eine weitere Möglichkeit, das Gleiche zu entdecken, besteht darin, einfach einen Streudiagramm der Kovariablen gegen das Ergebnis zu zeichnen. Abschließend wird durch den Scatterplot nochmals bestätigt, was wir bereits wissen: die Kovariable bewirkt, dass mit zunehmender Partnerlibido auch die Libido des Teilnehmers zunimmt (wie die Steigung der Regressionslinie zeigt). Post hoc Tests Wie bereits aus der ANOVA bekannt sein sollte, werden bei den Post hoc Tests alle Stufen der unabhängigen Variablen paarweise miteinander verglichen. Im Unterschied zur herkömmlichen ANOVA weden jedoch bei der ANCOVA die adjustierten Mittelwerte verwendet! Das Ergebnis zeigt die drei Vergleiche (niedrige Dosis vs. Placebo, hohe Dosis vs. Placebo, hohe Dosis vs. niedrige Dosis). Verglichen werden die Differenzen zu den adjustierten Gruppenmitteln die Schätzung für die niedrige Dosis vs. Placebo beträgt \\(4.71 - 2.93 = 1.78\\) für die hohe Dosis vs. Placebo beträgt sie \\(5.15 - 2.93 = 2.22\\) und für die niedrige vs. hohe \\(5.15 - 4.71 = 0.44\\) Der angegebene Standardfehler bezieht sich auf die Differenz zwischen den adjusiterten Mittelwerten. Der \\(t\\)-Test (Differenz zwischen den Mitteln geteilt durch den Standardfehler) und dem zugehörigen \\(p\\)-Wert deutet auf signifikante Unterschiede zwischen der Hochdosis- und Placebogruppe (\\(t = 2.77, p &lt; .050\\)) hin. Kein Unterschied besteht zwischen der Niedrigdosisgruppe und der Placebogruppe (\\(t = 2.10, p = .120\\)) und der Hochdosisgruppe (\\(t = 0.54, p = .850\\)). Die Konfidenzintervalle bestätigen diese Schlussfolgerung (weil sie für den Vergleich der Hochdosis- und Placebogruppen Null nicht enthalten). ## ## Simultaneous Tests for General Linear Hypotheses ## ## Multiple Comparisons of Means: Tukey Contrasts ## ## ## Fit: aov(formula = libido ~ partnerLibido + dose, data = viagraData) ## ## Linear Hypotheses: ## Estimate Std. Error t value Pr(&gt;|t|) ## Low Dose - Placebo == 0 1.786 0.849 2.10 0.109 ## High Dose - Placebo == 0 2.225 0.803 2.77 0.027 * ## High Dose - Low Dose == 0 0.439 0.811 0.54 0.852 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## (Adjusted p values reported -- single-step method) ## ## Simultaneous Confidence Intervals ## ## Multiple Comparisons of Means: Tukey Contrasts ## ## ## Fit: aov(formula = libido ~ partnerLibido + dose, data = viagraData) ## ## Quantile = 2.48 ## 95% family-wise confidence level ## ## ## Linear Hypotheses: ## Estimate lwr upr ## Low Dose - Placebo == 0 1.786 -0.324 3.896 ## High Dose - Placebo == 0 2.225 0.231 4.219 ## High Dose - Low Dose == 0 0.439 -1.576 2.454 Nützliche Graphen Zur Überprüfung von Voraussetzungen können sich folgende Graphiken als hilfreich erweisen: Von den vier Diagramme sind die ersten beiden die wichtigsten: Ersterer kann zur Überprüfung der Varianzhomogenität der Varianz verwendet werden. Es zeigt sich, dass die Verteilung der Scores an einigen Stellen breiter als an anderenis (Funnelling). Die Residuen sind also heteroscedastisch. Das zweite Diagramm ist ein Q-Q-Diagramm. Die Punkte im Diagramm sollten nahe der diagonalen Linie liegen. Die vorliegende Verteilung deutet darauf hin, dass keine Normalverteilung vorliegt und daher eher eine robuste ANCOVA6 angebracht wäre. Die dritte Graphik wird auch als Spread-Location-Plot bezeichnet. Diese Darstellung zeigt, ob die Residuen gleichmäßig über die Bereiche der Prädiktoren verteilt sind. So können Sie die Annahme der gleichen Varianz (Homoscedastizität) überprüfen. Es ist gut, wenn man eine horizontale Linie mit gleichmäßig (zufällig) gespreizten Punkten sehen - was hier nicht der Fall ist. Die vierte Graphik identifiziert einflussreiche Fälle (Ausreißer). Nicht alle Ausreißer beeinflussen die linearen Regressionsanalyse im negativen Sinn, d.h. die Ergebnisse wären nicht viel anders, wenn wir sie entweder einbeziehen oder von der Analyse ausschließen würden. Sie folgen in den meisten Fällen dem Trend und sind nicht wirklich wichtig. Andererseits können einige Fälle sehr einflussreich sein, auch wenn sie sich in einem angemessenen Bereich der Werte bewegen. Sie können Extremfälle gegen eine Regressionslinie sein und die Ergebnisse verändern, wenn wir sie von der Analyse ausschließen. Im Gegensatz zu den anderen Graphiken sind hier Muster nicht relevant. Man achtet auf die äußeren Werte in der oberen rechten Ecke oder in der unteren rechten Ecke. Diese Punkte sind die Orte, an die für eine Regressionslinie einflussreich sein können. Man beachtet vor allem Fälle, die außerhalb einer gestrichelten Linie (Cook’s Distance) sind. Werte die außerhalb liegen, sind für die Regressionsergebnisse von Bedeutung. Die Regressionsergebnisse werden geändert, wenn wir diese Fälle ausschließen! Homogenität der Steigung Bereits im Scatterplot der nach Gruppen getrennten Regressionen konnten wir feststellen, dass die Annahme der Homogenität der Regressionssteigungen für die Hochdosisgruppe unterschiedlich verletzt wird. Um einen statistischen Test dieser Annahme durchzufürhen, wird die ANCOVA unter Einbeziehung des Interaktionseffektes zwischen der Kovariaten und dem Prädiktor nochmals durchgeführt. Anova Table (Type III tests) Sum Sq Df F value Pr(&gt;F) (Intercept) 53.54 1 21.92 9.323e-05 partnerLibido 17.18 1 7.035 0.01395 dose 36.56 2 7.484 0.00298 partnerLibido:dose 20.43 2 4.181 0.02767 Residuals 58.62 24 NA NA Die Auswirkungen der Dosis von Viagra und der Libido des Partners sind immer noch signifikant, aber da die Interaktion (partnerLibido:dose) signifikant (\\(p = .028\\)) ist, ist die Annahme der Homogenität der Regressionsgeraden verletzt. Obwohl dieser Befund nicht überraschend ist (vgl. Graphik oben), gibt er Anlass zur Sorge über die Hauptanalyse. Dieses Beispiel veranschaulicht, warum es wichtig ist, Annahmen zu testen und nicht nur die Ergebnisse einer Analyse blind zu akzeptieren! Bericht der Ergebnisse Der Ergebnissbericht einer ANCOVA ist weitgehend identisch mit der einer ANOVA. Hinzu kommt lediglich die Wirkung der Kovariablen. Für die Kovariable und den experimentellen Effekt berichten wir Details über das \\(F\\)-Verhältnis und die Freiheitsgrade, aus denen es berechnet wurde. In beiden Fällen wurde das \\(F\\)-Verhältnis aus der Division der mittleren Quadrate für den Effekt durch die mittleren Quadrate der Residuen ermittelt. Die Freiheitsgrade zur Beurteilung des \\(F\\)-Wertes sind daher die Freiheitsgrade für die Wirkung des Modells (\\(df_M = 1\\) für die Kovariable und \\(2\\) für die experimentelle Wirkung) und die Freiheitsgrade für die Residuen des Modells (\\(df_R = 26\\) für die Kovariable und die experimentelle Wirkung). Der Bericht könnte folgendermaßen abgefasst werden: Die Kovariable (Libido des Partners) zeigt einen signifikanten Zusammenhang mit dem Libido des Teilnehmers (\\(F(1, 26) = 4.96, p &lt; .050, r = 0.40\\). Kontrolliert man für den Effelt des Libido’s des Partners, dann zeigt sich auch ein signifikanter Effekt der Dosis von Viagra auf den Libido (\\(F(2, 26) = 4.14, p &lt; .050, \\eta^2_{part} = .24\\)). Die geplanten Kontraste zeigten, dass die Einnahme einer hohen oder niedrigen Dosis von Viagra den Libido im Vergleich zur Einnahme eines Placebos signifikant erhöht (\\(t(26) = 2,79, p &lt; .010, r = 0.48\\)). Es gab keinen signifikanten Unterschied zwischen der hohen und niedrigen Dosis von Viagra (\\(t(26) = 0.54, p = .590, r = 0.11\\)). Die Tukey-Post-Hoc-Tests zeigten, dass der über die Kovariate angepasste Mittelwert der Hochdosis-Gruppe signifikant größer war als der des Placebos (Differenz = 2.22, \\(t = 2.77, p &lt; .050, d = 1,13\\)). Es gab jedoch keinen signifikanten Unterschied zwischen der Niedrigdosis- und Placebogruppe (Differenz = 1.79, \\(t = 2.10, p = .110, d = 1.04\\)) und zwischen der Niedrigdosis- und der Hochdosisgruppe (Differenz = 0.44, \\(t = 0.54, p = .850, d = 0.11\\)). Trotz der fehlenden Bedeutung zwischen der Niedrigdosis- und der Placebogruppe war die Effektgröße ziemlich groß. Es gibt noch andere Gründe für die Aufnahme von Kovariablen in die ANOVA, welche in der Berechnung der ANCOVA detailliert beschrieben werden. Siehe (Stevens 2002), (Wildt 2009).↩ wie oft sie versuchten, sexuellen Kontakt aufzunehmen.↩ möglicherweise kann man eine robuste Version des Tests ausführen, Details später.↩ Hartely’s \\(F_{max}\\) variance ratio.↩ für eine Liste vordefinierter Kontraste siehe Literatur. Kontraste können sowohl in SPSS wie auch in R durch entsprechende Kontrastcodierungen definiert werden. Bei R ist darauf zu achten, dass bei orthogonalen Kontrasten die Type III sum of squares verwendet wird, da sonst die Quatratsummen für derartige Kontraste nicht stimmen!↩ robuste ANCOVAS werden in dieser LV nicht näher besprochen - siehe Literatur.↩ "],
["referenzen.html", "Referenzen", " Referenzen "]
]
